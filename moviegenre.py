# -*- coding: utf-8 -*-
"""moviegenre.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AkuIUlHrpI1zo7T64_HDKbO4fyiGcFlV
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re  # used for pattern matching and text manipulation.
import string
import nltk #a powerful library for working with human language data.
from nltk.corpus import stopwords #for cleaning
from nltk.stem import LancasterStemmer ##for cleaning
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

data=pd.read_csv(r"/content/train_data.csv",sep=':::', names=['Title', 'Genre', 'Description'], engine='python')
data.describe()

data.head()

data.info()

print(data.info)

data.isnull().sum()

plt.figure(figsize=(10,15))
sns.countplot(data=data, y="Genre", order= data["Genre"].value_counts().index)
plt.show()

plt.figure(figsize=(27,7))

sns.countplot(data=data, x="Genre", order= data["Genre"].value_counts().index, hue="Genre", legend=False)
plt.show()

import nltk
nltk.download('stopwords')

stemmer = LancasterStemmer()
stop_words = set(stopwords.words("english"))  # Stopwords set

def cleaning_data(text):
    text = text.lower()
    text = re.sub(r'@\S+', '', text)
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'.pic\S+', '', text)
    text = re.sub(r'[^a-zA-Z+]', ' ', text)  # Change to replace non-characters with a space
    text = "".join([i for i in text if i not in string.punctuation])
    words = nltk.word_tokenize(text)
    # Use the predefined stop_words variable instead of redefining it inside the function
    text = " ".join([i for i in words if i not in stop_words and len(i) > 2])
    text = re.sub(r"\s+", " ", text).strip()  # Replace multiple spaces with a single space
    return text

data["TextCleaning"] = data["Description"].apply(cleaning_data)
data["TextCleaning"] = data["Description"].apply(cleaning_data)

data

vectorize = TfidfVectorizer()

X_train = vectorize.fit_transform(data["TextCleaning"])

X_test = vectorize.transform(data["TextCleaning"])

X = X_train
y = data["Genre"]

X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size= 0.4, random_state=42)

from sklearn.linear_model import LogisticRegression
classifier = LogisticRegression(random_state = 42)
classifier.fit(X_train, Y_train)

classifier.score(X_train,Y_train)

y_pred = classifier.predict(X_test)
y_pred

accuracy = accuracy_score(Y_test, y_pred)
print("Validation Accuracy:", accuracy)